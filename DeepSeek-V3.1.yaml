x-logging-conf: &logging-conf
  driver: "json-file"
  options:
    max-size: "100m"
    max-file: "10"
    labels: "com.datadoghq.ad.logs"

x-vllm-healthcheck: &vllm-healthcheck
  test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
  interval: 10s
  timeout: 10s
  retries: 100
  start_period: 3600s

x-nvidia: &nvidia
  runtime: nvidia
  ipc: host
  ulimits:
    memlock: -1
    nofile:
      soft: 65535
      hard: 65535

x-vllm-common: &vllm-common
  <<: *nvidia
  volumes:
    - hugginface_cache:/root/.cache/huggingface
    - vllm_cache:/root/.cache/vllm
  healthcheck: *vllm-healthcheck
  restart: unless-stopped
  logging: *logging-conf

x-vllm-proxy-common: &vllm-proxy-common
  image: nearaidev/vllm-proxy@sha256:0b1c4d010cd189c694650cce8f437734e2005ea65955797561d36710210eb4c2
  user: root
  privileged: true
  <<: *nvidia
  volumes:
    - /var/run/dstack.sock:/var/run/dstack.sock
  restart: unless-stopped
  environment:
    - NVIDIA_VISIBLE_DEVICES=all
  logging: *logging-conf

services:
  nginx:
    image: nginx@sha256:1d13701a5f9f3fb01aaa88cef2344d65b6b5bf6b7d9fa4cf0dca557a8d7702ba
    container_name: nginx
    command: /bin/sh -c 'while :; do sleep 6h; nginx -s reload; done & nginx -g "daemon off;"'
    ports:
      - "8000:80"
      - "8444:443"
    volumes:
      - certs:/etc/letsencrypt:ro
    configs:
      - source: nginx_conf
        target: /etc/nginx/conf.d/default.conf
        mode: 0644
    restart: unless-stopped
    logging: *logging-conf

  vllm-proxy-deepseek:
    <<: *vllm-proxy-common
    container_name: vllm-proxy-deepseek
    volumes:
      - /var/run/dstack.sock:/var/run/dstack.sock
      - certs:/etc/letsencrypt:ro
    environment:
      - MODEL_NAME=deepseek-ai/DeepSeek-V3.1
      - TOKEN=${PROXY_TOKEN}
      - VLLM_BASE_URL=http://vllm-deepseek:8000
      - TLS_CERT_PATH=/etc/letsencrypt/live/completions.near.ai/fullchain.pem
    labels:
      com.datadoghq.ad.logs: '[{"source": "vllm-proxy", "service": "vllm-proxy", "tags": ["model:deepseek-ai/DeepSeek-V3.1", "ip:${HOST_IP}", "port:8000"]}]'

  vllm-deepseek:
    <<: *vllm-common
    image: lmcache/vllm-openai@sha256:a4505b3422c4e3b93acba7f643ff7c1a3d5a2deb7bc74f943fffe1d23aa02f1a
    container_name: vllm-deepseek
    command: >
        deepseek-ai/DeepSeek-V3.1
        --tensor-parallel-size 8
        --max-model-len 128K
        --max-num-batched-tokens 32K
        --max-num-seqs 64
        --all2all-backend deepep_low_latency
        --speculative-config '{"method": "deepseek_mtp", "num_speculative_tokens": 1}'
        --kv-transfer-config '{"kv_connector":"LMCacheConnectorV1","kv_role":"kv_both"}'
        --stream-interval 6
        --chat-template /vllm-workspace/examples/tool_chat_template_deepseekv31.jinja
        --trust-remote-code
        --enable-auto-tool-choice
        --tool-call-parser deepseek_v31
        --reasoning-parser deepseek_v3

    volumes:
      - hugginface_cache:/root/.cache/huggingface
      - vllm_cache:/root/.cache/vllm
    configs:
      - source: chat_template_deepseek
        target: /vllm-workspace/examples/tool_chat_template_deepseekv31.jinja
        mode: 0644
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - VLLM_LOGGING_LEVEL=INFO
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OPENBLAS_L2_SIZE=2097152
      - NCCL_DEBUG=INFO
      - VLLM_CACHE_ROOT=/root/.cache/vllm
      - TORCH_FLOAT32_MATMUL_PRECISION=high
      - LMCACHE_CHUNK_SIZE=256
      - LMCACHE_LOCAL_CPU=True
      - LMCACHE_MAX_LOCAL_CPU_SIZE=100
      - PYTHONHASHSEED=0
      - VLLM_RPC_TIMEOUT=60000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0","1","2","3","4","5","6","7"]
              capabilities: [gpu]
    labels:
      com.datadoghq.ad.check_names: '["vllm"]'
      com.datadoghq.ad.init_configs: "[{}]"
      com.datadoghq.ad.logs: '[{"source": "vllm", "service": "vllm", "tags":["model:deepseek-ai/DeepSeek-V3.1","ip:${HOST_IP}", "port:8000"]}]'
      com.datadoghq.ad.instances: '[{"openmetrics_endpoint":"http://vllm-deepseek:8000/metrics", "service": "vllm-deepseek", "tags":["model:deepseek-ai/DeepSeek-V3.1","ip:${HOST_IP}", "port:8000"]}]'

networks:
  default:
    external: true
    name: dstack_default

volumes:
  hugginface_cache:
  vllm_cache:
  certs:
    external: true
    name: certs

configs:
  nginx_conf:
    content: |
      server {
          listen 80 default_server;

          client_max_body_size 100m;

          location / {
              proxy_pass http://vllm-proxy-deepseek:8000;
              proxy_http_version 1.1;
              proxy_set_header Host $$host;
              proxy_set_header X-Real-IP $$remote_addr;
              proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $$scheme;
              proxy_set_header Connection '';
              proxy_buffering off;
              proxy_cache off;
              proxy_read_timeout 300s;
          }
      }

      server {
          listen 443 ssl;
          server_name deepseek-v31.completions.near.ai;

          ssl_certificate /etc/letsencrypt/live/completions.near.ai/fullchain.pem;
          ssl_certificate_key /etc/letsencrypt/live/completions.near.ai/privkey.pem;
          ssl_protocols TLSv1.2 TLSv1.3;

          client_max_body_size 100m;

          location / {
              proxy_pass http://vllm-proxy-deepseek:8000;
              proxy_http_version 1.1;
              proxy_set_header Host $$host;
              proxy_set_header X-Real-IP $$remote_addr;
              proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $$scheme;
              proxy_set_header Connection '';
              proxy_buffering off;
              proxy_cache off;
              proxy_read_timeout 300s;
          }
      }
  chat_template_deepseek:
    content: |
      {% if not add_generation_prompt is defined %}
        {% set add_generation_prompt = false %}
      {% endif %}
      {% if not thinking is defined %}
        {% set thinking = false %}
      {% endif %}
      {% set ns = namespace(is_first=false, is_tool=false, system_prompt='', is_first_sp=true, is_last_user=false) %}
      {%- for message in messages %}
        {%- if message['role'] == 'system' %}
          {%- if ns.is_first_sp %}
            {% set ns.system_prompt = ns.system_prompt + message['content'] %}
            {% set ns.is_first_sp = false %}
          {%- else %}
            {% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}
          {%- endif %}
        {%- endif %}
      {%- endfor %}

      {% if tools is defined and tools is not none %}
        {% set tool_ns = namespace(text='## Tools\nYou have access to the following tools:\n') %}
        {% for tool in tools %}
          {% set tool_ns.text = tool_ns.text + '\n### ' + tool.function.name + '\nDescription: ' + tool.function.description + '\n\nParameters: ' + (tool.function.parameters | tojson) + '\n' %}
        {% endfor %}
        {% set tool_ns.text = tool_ns.text + "\nIMPORTANT: ALWAYS adhere to this exact format for tool use:\n<｜tool▁calls▁begin｜><｜tool▁call▁begin｜>tool_call_name<｜tool▁sep｜>tool_call_arguments<｜tool▁call▁end｜>{{additional_tool_calls}}<｜tool▁calls▁end｜>\n\nWhere:\n\n- `tool_call_name` must be an exact match to one of the available tools\n- `tool_call_arguments` must be valid JSON that strictly follows the tool's Parameters Schema\n- For multiple tool calls, chain them directly without separators or spaces\n" %}
        {% set ns.system_prompt = ns.system_prompt + '\n\n' + tool_ns.text %}
      {% endif %}

      {{ bos_token }}{{ ns.system_prompt }}
      {%- for message in messages %}
        {%- if message['role'] == 'user' %}
          {%- set ns.is_tool = false -%}
          {%- set ns.is_first = false -%}
          {%- set ns.is_last_user = true -%}
          {{'<｜User｜>' + message['content']}}
        {%- endif %}
        {%- if message['role'] == 'assistant' and message['tool_calls'] is defined and message['tool_calls'] is not none %}
          {%- if ns.is_last_user %}
            {{'<｜Assistant｜></think>'}}
          {%- endif %}
          {%- set ns.is_last_user = false -%}
          {%- set ns.is_first = false %}
          {%- set ns.is_tool = false -%}
          {%- for tool in message['tool_calls'] %}
            {%- if not ns.is_first %}
              {%- if message['content'] is none %}
                {{'<｜tool▁calls▁begin｜><｜tool▁call▁begin｜>'+ tool['function']['name'] + '<｜tool▁sep｜>' + tool['function']['arguments']|tojson + '<｜tool▁call▁end｜>'}}
              {%- else %}
                {{message['content'] + '<｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['function']['name'] + '<｜tool▁sep｜>' + tool['function']['arguments']|tojson + '<｜tool▁call▁end｜>'}}
              {%- endif %}
              {%- set ns.is_first = true -%}
            {%- else %}
              {{'<｜tool▁call▁begin｜>'+ tool['function']['name'] + '<｜tool▁sep｜>' + tool['function']['arguments']|tojson + '<｜tool▁call▁end｜>'}}
            {%- endif %}
          {%- endfor %}
          {{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}
        {%- endif %}
        {%- if message['role'] == 'assistant' and (message['tool_calls'] is not defined or message['tool_calls'] is none) %}
          {%- if ns.is_last_user %}
            {{'<｜Assistant｜>'}}
            {%- if message['prefix'] is defined and message['prefix'] and thinking %}
              {{'<think>'}}
            {%- else %}
              {{'</think>'}}
            {%- endif %}
          {%- endif %}
          {%- set ns.is_last_user = false -%}
          {%- if ns.is_tool %}
            {{message['content'] + '<｜end▁of▁sentence｜>'}}
            {%- set ns.is_tool = false -%}
          {%- else %}
            {%- set content = message['content'] -%}
            {%- if '</think>' in content %}
              {%- set content = content.split('</think>', 1)[1] -%}
            {%- endif %}
            {{content + '<｜end▁of▁sentence｜>'}}
          {%- endif %}
        {%- endif %}
        {%- if message['role'] == 'tool' %}
          {%- set ns.is_last_user = false -%}
          {%- set ns.is_tool = true -%}
          {{'<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}
        {%- endif %}
      {%- endfor -%}
      {%- if add_generation_prompt and ns.is_last_user and not ns.is_tool %}
        {{'<｜Assistant｜>'}}
        {%- if not thinking %}
          {{'</think>'}}
        {%- else %}
          {{'<think>'}}
        {%- endif %}
      {% endif %}