x-logging-conf: &logging-conf
  driver: "json-file"
  options:
    max-size: "100m"
    max-file: "10"
    labels: "com.datadoghq.ad.logs"

x-vllm-healthcheck: &vllm-healthcheck
  test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
  interval: 10s
  timeout: 10s
  retries: 100
  start_period: 3600s

x-nvidia: &nvidia
  runtime: nvidia
  ipc: host
  privileged: true
  ulimits:
    memlock: -1
    nofile:
      soft: 65535
      hard: 65535

x-vllm-common: &vllm-common
  <<: *nvidia
  volumes:
    - hugginface_cache:/root/.cache/huggingface
    - vllm_cache:/root/.cache/vllm
  healthcheck: *vllm-healthcheck
  restart: unless-stopped
  logging: *logging-conf

x-vllm-proxy-common: &vllm-proxy-common
  image: nearaidev/vllm-proxy@sha256:7fff3d0446a01609e6a45105ef60777bb6038805161793b50c2d8e4a34ac537b
  user: root
  <<: *nvidia
  volumes:
    - /var/run/dstack.sock:/var/run/dstack.sock
  restart: unless-stopped
  environment:
    - NVIDIA_VISIBLE_DEVICES=all
  logging: *logging-conf

services:
  nginx:
    image: nginx:alpine
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - certs:/etc/letsencrypt:ro
    configs:
      - source: nginx_conf
        target: /etc/nginx/conf.d/default.conf
        mode: 0644
    depends_on:
      - vllm-proxy-glm
    restart: unless-stopped
    logging: *logging-conf

  vllm-proxy-glm:
    <<: *vllm-proxy-common
    container_name: vllm-proxy-glm
    ports:
      - "8000:8000"
    environment:
      - MODEL_NAME=zai-org/GLM-4.7
      - TOKEN=${PROXY_TOKEN}
      - VLLM_BASE_URL=http://vllm-glm:8000
    labels:
      com.datadoghq.ad.logs: '[{"source": "vllm-proxy", "service": "vllm-proxy", "tags": ["model:zai-org/GLM-4.7", "ip:${HOST_IP}", "port:8000"]}]'

  vllm-glm:
    <<: *vllm-common
    image: lmcache/vllm-openai@sha256:a4505b3422c4e3b93acba7f643ff7c1a3d5a2deb7bc74f943fffe1d23aa02f1a
    container_name: vllm-glm
    command: >
        zai-org/GLM-4.7
        --tensor-parallel-size 8
        --speculative-config '{"method":"mtp","num_speculative_tokens":1}'
        --kv-transfer-config '{"kv_connector":"LMCacheConnectorV1","kv_role":"kv_both"}'
        --max-model-len 128K
        --max-num-batched-tokens 32K
        --max-num-seqs 128
        --stream-interval 6
        --reasoning-parser glm45
        --tool-call-parser glm47
        --enable-auto-tool-choice
    volumes:
      - hugginface_cache:/root/.cache/huggingface
      - vllm_cache:/root/.cache/vllm
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - VLLM_LOGGING_LEVEL=INFO
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OPENBLAS_L2_SIZE=2097152
      - NCCL_DEBUG=INFO
      - VLLM_CACHE_ROOT=/root/.cache/vllm
      - TORCH_FLOAT32_MATMUL_PRECISION=high
      - LMCACHE_CHUNK_SIZE=256
      - LMCACHE_LOCAL_CPU=True
      - LMCACHE_MAX_LOCAL_CPU_SIZE=100
      - PYTHONHASHSEED=0
      - VLLM_RPC_TIMEOUT=60000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0","1","2","3","4","5","6","7"]
              capabilities: [gpu]
    labels:
      com.datadoghq.ad.check_names: '["vllm"]'
      com.datadoghq.ad.init_configs: "[{}]"
      com.datadoghq.ad.logs: '[{"source": "vllm", "service": "vllm", "tags":["model:zai-org/GLM-4.7","ip:${HOST_IP}", "port:8000"]}]'
      com.datadoghq.ad.instances: '[{"openmetrics_endpoint":"http://vllm-glm:8000/metrics", "service": "vllm-glm", "tags":["model:zai-org/GLM-4.7","ip:${HOST_IP}", "port:8000"]}]'

volumes:
  hugginface_cache:
  vllm_cache:
  certs:
    external: true
    name: certs


configs:
  nginx_conf:
    content: |
      server {
          listen 80;
          listen 443 ssl;

          ssl_certificate /etc/letsencrypt/live/completions.near.ai/fullchain.pem;
          ssl_certificate_key /etc/letsencrypt/live/completions.near.ai/privkey.pem;
          ssl_protocols TLSv1.2 TLSv1.3;

          client_max_body_size 100m;

          location / {
              proxy_pass http://vllm-proxy-glm:8000;
              proxy_http_version 1.1;
              proxy_set_header Host $$host;
              proxy_set_header X-Real-IP $$remote_addr;
              proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $$scheme;
              proxy_set_header Connection '';
              proxy_buffering off;
              proxy_cache off;
              proxy_read_timeout 300s;
          }
      }
  journald_config_file:
    content: |
      logs:
        - type: journald
          container_mode: true