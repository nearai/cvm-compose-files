x-logging-conf: &logging-conf
  driver: "json-file"
  options:
    max-size: "100m"
    max-file: "10"
    labels: "com.datadoghq.ad.logs"

x-vllm-healthcheck: &vllm-healthcheck
  test: ["CMD", "curl", "-f", "http://localhost:8000/v1/models"]
  interval: 10s
  timeout: 10s
  retries: 100
  start_period: 3600s

x-nvidia: &nvidia
  runtime: nvidia
  ipc: host
  privileged: true
  ulimits:
    memlock: -1
    nofile:
      soft: 65535
      hard: 65535

x-vllm-common: &vllm-common
  <<: *nvidia
  volumes:
    - hugginface_cache:/root/.cache/huggingface
    - vllm_cache:/root/.cache/vllm
  healthcheck: *vllm-healthcheck
  restart: unless-stopped
  logging: *logging-conf

x-vllm-proxy-common: &vllm-proxy-common
  image: nearaidev/vllm-proxy-rs@11494e75b77588a877931f4da2b5b6143c174ae1696bb0a2517bfba055fdb288
  user: root
  <<: *nvidia
  volumes:
    - /var/run/dstack.sock:/var/run/dstack.sock
  restart: unless-stopped
  environment:
    - NVIDIA_VISIBLE_DEVICES=all
  logging: *logging-conf

services:
  nginx:
    image: nginx@sha256:1d13701a5f9f3fb01aaa88cef2344d65b6b5bf6b7d9fa4cf0dca557a8d7702ba
    container_name: nginx
    command: /bin/sh -c 'while :; do sleep 6h; nginx -s reload; done & nginx -g "daemon off;"'
    ports:
      - "8000:80"
      - "8444:443"
    volumes:
      - certs:/etc/letsencrypt:ro
    configs:
      - source: nginx_conf
        target: /etc/nginx/conf.d/default.conf
        mode: 0644
    restart: unless-stopped
    logging: *logging-conf

  vllm-proxy-glm:
    <<: *vllm-proxy-common
    container_name: vllm-proxy-glm
    volumes:
      - /var/run/dstack.sock:/var/run/dstack.sock
      - certs:/etc/letsencrypt:ro
    environment:
      - MODEL_NAME=zai-org/GLM-4.7
      - TOKEN=${PROXY_TOKEN}
      - VLLM_BASE_URL=http://vllm-glm:8000
      - TLS_CERT_PATH=/etc/letsencrypt/live/completions.near.ai/fullchain.pem
    labels:
      com.datadoghq.ad.logs: '[{"source": "vllm-proxy", "service": "vllm-proxy", "tags": ["model:zai-org/GLM-4.7", "ip:${HOST_IP}", "port:8000"]}]'

  vllm-glm:
    <<: *vllm-common
    image: lmcache/vllm-openai@sha256:03a8cbda016be1ab5660d1e2910549cbadea85b1111a34572544c1e180538e8b
    container_name: vllm-glm
    command: >
        zai-org/GLM-4.7
        --tensor-parallel-size 8
        --max-model-len 202752
        --max-num-batched-tokens 32K
        --max-num-seqs 128
        --stream-interval 6
        --reasoning-parser glm45
        --tool-call-parser glm47
        --enable-auto-tool-choice
    volumes:
      - hugginface_cache:/root/.cache/huggingface
      - vllm_cache:/root/.cache/vllm
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - VLLM_LOGGING_LEVEL=INFO
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OPENBLAS_L2_SIZE=2097152
      - NCCL_DEBUG=INFO
      - VLLM_CACHE_ROOT=/root/.cache/vllm
      - TORCH_FLOAT32_MATMUL_PRECISION=high
      - LMCACHE_LOCAL_CPU=False
      - PYTHONHASHSEED=0
      - VLLM_RPC_TIMEOUT=60000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0","1","2","3","4","5","6","7"]
              capabilities: [gpu]
    labels:
      com.datadoghq.ad.check_names: '["vllm"]'
      com.datadoghq.ad.init_configs: "[{}]"
      com.datadoghq.ad.logs: '[{"source": "vllm", "service": "vllm", "tags":["model:zai-org/GLM-4.7","ip:${HOST_IP}", "port:8000"]}]'
      com.datadoghq.ad.instances: '[{"openmetrics_endpoint":"http://vllm-glm:8000/metrics", "service": "vllm-glm", "tags":["model:zai-org/GLM-4.7","ip:${HOST_IP}", "port:8000"]}]'

volumes:
  hugginface_cache:
  vllm_cache:
  certs:
    external: true
    name: certs


configs:
  nginx_conf:
    content: |
      server {
          listen 80 default_server;

          client_max_body_size 100m;

          location / {
              proxy_pass http://vllm-proxy-glm:8000;
              proxy_http_version 1.1;
              proxy_set_header Host $$host;
              proxy_set_header X-Real-IP $$remote_addr;
              proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $$scheme;
              proxy_set_header Connection '';
              proxy_buffering off;
              proxy_cache off;
              proxy_read_timeout 300s;
          }
      }

      server {
          listen 443 ssl;
          server_name glm-47.completions.near.ai;

          ssl_certificate /etc/letsencrypt/live/completions.near.ai/fullchain.pem;
          ssl_certificate_key /etc/letsencrypt/live/completions.near.ai/privkey.pem;
          ssl_protocols TLSv1.2 TLSv1.3;

          client_max_body_size 100m;

          location / {
              proxy_pass http://vllm-proxy-glm:8000;
              proxy_http_version 1.1;
              proxy_set_header Host $$host;
              proxy_set_header X-Real-IP $$remote_addr;
              proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Proto $$scheme;
              proxy_set_header Connection '';
              proxy_buffering off;
              proxy_cache off;
              proxy_read_timeout 300s;
          }
      }